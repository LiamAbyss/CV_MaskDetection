{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Notebook\n",
    "\n",
    "Download the dataset and extract its contents into the root folder, then run the notebook to train the AI and try it.\n",
    "If you don't want to train the AI, you can extract the pretrained model \"svm_model.zip\" and run the last cell directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin loading images from Masked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 283/283 [00:00<00:00, 1209.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading images from Masked\n",
      "Begin loading images from Unmasked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 350/350 [00:00<00:00, 1199.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading images from Unmasked\n",
      "Begin loading images from Half_Masked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 349/349 [00:00<00:00, 1185.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading images from Half_Masked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the used directories (same as labels)\n",
    "label_names = [\"Masked\", \"Unmasked\", \"Half_Masked\"]\n",
    "\n",
    "# Use it if you want to limit the number of images per category\n",
    "# to avoid long loading times\n",
    "# Set it to 0 or less to have no limit\n",
    "limit = 0\n",
    "\n",
    "faces = []\n",
    "labels = []\n",
    "\n",
    "for id, d in enumerate(label_names):\n",
    "    print(\"Begin loading images from \" + d)\n",
    "    time.sleep(.5)\n",
    "    files = os.listdir('Output/faces/' + d)\n",
    "\n",
    "    max_files = min(limit, len(files)) if limit > 0 else len(files)\n",
    "    # Load every image (in the defined limit),\n",
    "    # resize them to 250x250px\n",
    "    # and convert them to grayscales\n",
    "    with tqdm(total=max_files) as pbar:\n",
    "        for x,f in enumerate(files):\n",
    "            if x >= max_files:\n",
    "                break\n",
    "            faces += [cv2.cvtColor(cv2.resize(cv2.imread('./Output/faces/'+ d + '/' + f), (250, 250), interpolation=cv2.INTER_AREA), cv2.COLOR_BGR2GRAY)]    \n",
    "            pbar.update(1)\n",
    "\n",
    "    # Fill the labels according to the index of the directory name\n",
    "    # Example : 0 for 'Masked', 1 for 'Unmasked' and 2 for 'Half_Masked'\n",
    "    labels += [id] * (len(faces)-len(labels))\n",
    "\n",
    "    print(\"Finished loading images from \" + d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 982/982 [00:00<00:00, 25758.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(283, 62500)\n",
      "(350, 62500)\n",
      "(349, 62500)\n",
      "(982, 62500)\n",
      "(982,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with_mask = []\n",
    "without_mask = []\n",
    "half_masked = []\n",
    "\n",
    "with tqdm(total=len(faces)) as pbar:\n",
    "    for f, l in zip(faces, labels):\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # transform the image to a numpy array\n",
    "        data = np.array(f)\n",
    "        # reshape the image to a linear array\n",
    "        data = data.reshape(1, -1)\n",
    "        if l == 0:\n",
    "            with_mask.append(data)\n",
    "        elif l == 1:\n",
    "            without_mask.append(data)\n",
    "        elif l == 2:\n",
    "            half_masked.append(data)\n",
    "        else:\n",
    "            dumbass.append(data)\n",
    "\n",
    "with_mask = np.array(with_mask).reshape(len(with_mask), -1)\n",
    "without_mask = np.array(without_mask).reshape(len(without_mask), -1)\n",
    "half_masked = np.array(half_masked).reshape(len(half_masked), -1)\n",
    "\n",
    "print(with_mask.shape)\n",
    "print(without_mask.shape)\n",
    "print(half_masked.shape)\n",
    "\n",
    "# concatenate the arrays \n",
    "X = np.r_[with_mask, without_mask, half_masked]\n",
    "print(X.shape)\n",
    "\n",
    "labels = np.array(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 62500)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=np.random.randint(0,9999))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'svm_model.sav'\n",
    "\n",
    "# You can load the model if you want to train over the previous trainings\n",
    "#svm = joblib.load(filename)\n",
    "svm = SVC(kernel='rbf', C=4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.8934010152284264\n"
     ]
    }
   ],
   "source": [
    "svm.fit(x_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.sav']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "svm = joblib.load(filename)\n",
    "\n",
    "colors = [\n",
    "    (0, 255, 0),\n",
    "    (0, 0, 255),\n",
    "    (0, 255, 255)\n",
    "]\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_detection.FaceDetection(\n",
    "    model_selection=0, min_detection_confidence=0.6) as face_detection:\n",
    "    while(vid.isOpened()):#True):\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        # Capture the video frame\n",
    "        # by frame\n",
    "        ret, img = vid.read()\n",
    "        cv2.flip(img, 1, img)\n",
    "        \n",
    "        img.flags.writeable = False\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect faces\n",
    "        results = face_detection.process(img)\n",
    "\n",
    "        # Draw the face detection annotations on the image.\n",
    "        img.flags.writeable = True\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if i == 0:\n",
    "            try:\n",
    "                if results.detections:\n",
    "                    for detection in results.detections:\n",
    "                        # Get the bounding box of the face\n",
    "                        # and its characteristics\n",
    "                        bb = detection.location_data.relative_bounding_box\n",
    "                        x = bb.xmin\n",
    "                        y = bb.ymin\n",
    "                        h = bb.height\n",
    "                        w = bb.width\n",
    "\n",
    "                        camWidth = img.shape[1]\n",
    "                        camHeight = img.shape[0]\n",
    "\n",
    "                        # Convert x, y, h and w from percentages to pixels\n",
    "                        x = int(x * camWidth)\n",
    "                        y = int(y * camHeight)\n",
    "                        h = int(h * camHeight)\n",
    "                        w = int(w * camWidth)\n",
    "\n",
    "                        # Resize the face capture and grayscale\n",
    "                        toPredict = cv2.resize(img[y:y+h, x:x+w], (250, 250), interpolation = cv2.INTER_AREA)\n",
    "                        toPredict = cv2.cvtColor(toPredict, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                        # Reshape the data\n",
    "                        toPredict = toPredict.reshape(1, -1)\n",
    "\n",
    "                        # Predict\n",
    "                        pred = svm.predict(toPredict)\n",
    "                        pred = int(pred[0])\n",
    "\n",
    "                        # if the predicted label is in the list of known labels, draw a rectangle around the face and label it\n",
    "                        if pred < len(label_names):\n",
    "                            cv2.rectangle(img,(x,y),(x+w,y+h),colors[pred],2)\n",
    "                            cv2.putText(img, label_names[pred], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.2, colors[pred], 3)\n",
    "            except:\n",
    "                pass\n",
    "        i = (i + 1) % 3\n",
    "        img = cv2.resize(img, (0, 0), fx = 1.5, fy = 1.5)\n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame', img)\n",
    "        \n",
    "        # the 'q' button is set as the\n",
    "        # quitting button you may use any\n",
    "        # desired button of your choice\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # After the loop release the cap object\n",
    "    vid.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8457d5f13b68ea6baddc1bbfa45220c29b0ac974c0b776b8f1dc3cf598baeca6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
